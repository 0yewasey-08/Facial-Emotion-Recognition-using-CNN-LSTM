Facial Emotion Recognition Using CNNâ€“LSTM By Abdul Wasey

Abstract
Facial Emotion Recognition (FER) is an important research area in computer vision and affective computing. This project presents a deep learningâ€“based facial emotion recognition system using a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) architecture. The model is trained on the FER2013 dataset and optimized using the Adam optimizer. Experimental results demonstrate that the proposed approach effectively classifies facial expressions into seven emotion categories with competitive accuracy.

1. Introduction
Human emotions play a crucial role in communication and decision-making. Automatic facial emotion recognition has applications in humanâ€“computer interaction, healthcare, surveillance, education, and entertainment. However, recognizing emotions from facial images is challenging due to variations in lighting, pose, occlusion, and subtle differences between expressions. This project aims to design and implement a robust facial emotion recognition system using deep learning techniques.

3. Objectives
The main objectives of this project are:
â€¢ To study facial emotion recognition using deep learning.
â€¢ To implement a CNN-based feature extractor for facial images.
â€¢ To integrate an LSTM network to learn feature dependencies.
â€¢ To train and evaluate the model on the FER2013 dataset.
â€¢ To analyze model performance using accuracy and confusion matrix.

4. Dataset Description
FER2013 Dataset
Image size: 48 Ã— 48 grayscale
Total images: 35,887
Classes: 7 emotions
Dataset link:
ðŸ‘‰ https://www.kaggle.com/datasets/msambare/fer2013

The dataset is challenging due to low image resolution, noise, and class imbalance.

5. Methodology
The proposed system follows a multi-stage pipeline consisting of data preprocessing, feature extraction, sequence learning, and classification.

5.1 Data Preprocessing and Augmentation
All images are resized to 48Ã—48 pixels and normalized to the range [0,1]. Data augmentation techniques such as rotation, width and height shifting, zooming, shearing, and horizontal flipping are applied to increase dataset diversity and reduce overfitting.

5.2 CNN Feature Extraction
The Convolutional Neural Network (CNN) is used to extract spatial features from facial images. Multiple convolutional layers with ReLU activation functions are employed, followed by max pooling and batch normalization layers. Dropout is applied to improve generalization.

5.3 LSTM for Feature Dependency Learning
After CNN-based feature extraction, the features are reshaped and passed to an LSTM layer. The LSTM network captures dependencies between extracted features, enhancing the modelâ€™s ability to recognize subtle emotional patterns.

5.4 Classification and Optimization
The model is trained using the Adam optimizer, which adaptively adjusts the learning rate for faster and more stable convergence. Categorical cross-entropy is used as the loss function.

7. Model Architecture
The proposed CNNâ€“LSTM architecture consists of:
â€¢ Three convolutional blocks (Conv2D + Batch Normalization + MaxPooling + Dropout)
â€¢ A Flatten layer
â€¢ A Reshape layer to prepare features for LSTM
â€¢ One LSTM layer
â€¢ A Dense Softmax output layer with seven neurons

This hybrid architecture combines spatial and sequential learning capabilities.

8. Training and Evaluation
The model is trained for multiple epochs with a batch size of 64. Validation data is used to monitor performance and prevent overfitting. Model performance is evaluated using accuracy and confusion matrix on the test dataset.

9. Results and Discussion
The CNNâ€“LSTM model achieved improved accuracy compared to a baseline CNN model. Data augmentation and the Adam optimizer contributed to stable training and better generalization. The confusion matrix shows that emotions such as Happy and Surprise are recognized with higher accuracy, while Fear and Disgust remain more challenging due to visual similarities.

10. Conclusion
This project successfully implemented a facial emotion recognition system using a CNNâ€“LSTM hybrid model. The use of the Adam optimizer and data augmentation improved training stability and accuracy. Experimental results confirm the effectiveness of deep learning techniques for emotion recognition tasks.

